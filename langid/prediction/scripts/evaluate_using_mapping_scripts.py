# -*- coding: utf-8 -*-
"""Evaluate using mapping scripts

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zydGkFd414PapPQ0ywfHgGGNZ63dRUi7
"""

from dataclasses import dataclass, asdict
from typing import Any
import datetime
import sys
from pathlib import Path
import json
import importlib
import os

from datasets import Audio
from transformers import AutoModelForAudioClassification, AutoFeatureExtractor
import torch


def main(**kwargs):
  """
  Run LI on a given file
  """

  model_id = kwargs.get("model_id")
  filepath = kwargs.get("filepath")

  ## Build output path
  iso_now = datetime.now().isoformat().replace(':', '-').replace('.', '-')
  output_dir = Path("/output") / model_id.replace('/', '_') / iso_now
  output_dir.mkdir(parents=True, exist_ok=True)
  mappings_dir = Path("/app/mappings")
  mappings_dir.mkdir(parents=True, exist_ok=True)

  ## STEPS:
  # Load model 
  model, feature_extractor = load_model(model_id)
  # Load data
  audio_array = load_local_data(filepath)
  ## Get model mappings
  ## I am not entirely sure that we need the mapping in this case, but maybe this is to make it more universal 
  model_id_to_global_id, global_id_to_model_id = load_mappings(mappings_dir, model_id)
  ## Run predictions
  predict(model, audio_array, feature_extractor, model_id_to_global_id)
  ##TODO: Add a function to output the predictions

def load_model(model_id):
  """
  Loads the model amd feature extractor according to model_id
  """
  model = AutoModelForAudioClassification.from_pretrained(model_id)
  feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)
  return model, feature_extractor

def load_local_data(filepath):
  """
  loads local data into a dataset using HuggingFace Audio to extract audio from the files
  """
  return Audio(sampling_rate=16000).decode_example(filepath)

def load_mappings(mappings_dir, model_id):
  """
  Loads the mappings for the models 
  """
  model_mappings_dir = mappings_dir / "models" / model_id

  def load_mapping(path: Path):
    with open(path, "r") as in_file:
      mapping = json.load(in_file)
    mapping_integer_keys = {int(k): v for k, v in mapping.items()}
    return mapping_integer_keys

  ## Maps any deprecated language identifiers to their new values
  model_id_to_global_id = load_mapping(model_mappings_dir / "model_id_to_global_id.json")
  global_id_to_model_id = load_mapping(model_mappings_dir / "global_id_to_model_id.json")

  return model_id_to_global_id, global_id_to_model_id

def predict(model, audio_array, feature_extractor, model_id_to_global_id):
  """
  Prediction on an audio_array of a single file using specified model
  """
  inputs = feature_extractor(audio_array, sampling_rate=16000, return_tensors="pt")
  with torch.no_grad():
    outputs = model(**inputs)
    # get id with highest predicted score
    predicted_id = outputs.logits.argmax(dim=-1).tolist()
    ## change to readable language labels
    prediction = model_id_to_global_id[predicted_id]
  print(f'predicted_langs: {prediction}')
  return prediction

# """# Make inferences"""
# def make_inferences(output_dir, model, model_dataset, compute_metrics):
#   """
#   Returns prediction output
#   """
#   args = TrainingArguments(
#       output_dir=output_dir,
#       per_device_eval_batch_size=1,
#       logging_steps=25,
#   )

#   trainer = Trainer(
#       args=args,
#       model=model,
#       eval_dataset=model_dataset,
#       compute_metrics=compute_metrics,
#   )

#   return trainer.predict(model_dataset)